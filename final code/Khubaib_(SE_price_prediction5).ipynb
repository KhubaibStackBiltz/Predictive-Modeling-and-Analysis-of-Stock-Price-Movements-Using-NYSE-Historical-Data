{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Define Lstm Model"
      ],
      "metadata": {
        "id": "QyzlgkrGKdLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to load data for a given time step\n",
        "def load_data(time_steps):\n",
        "    dir_path = f'/content/drive/MyDrive/NYSE_Dataset/time_steps_{time_steps}'\n",
        "    X_train = np.load(os.path.join(dir_path, 'X_train.npy'))\n",
        "    X_test = np.load(os.path.join(dir_path, 'X_test.npy'))\n",
        "    y_train = np.load(os.path.join(dir_path, 'y_train.npy'))\n",
        "    y_test = np.load(os.path.join(dir_path, 'y_test.npy'))\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Function to build the LSTM model\n",
        "def build_model(units, learning_rate):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=units, activation='tanh', return_sequences=False, input_shape=(time_steps, num_features)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units=1))\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "99Lo3DARjbCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "rFqB7JfvKgOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of time steps\n",
        "time_steps_list = [1, 2, 5, 10]\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'units': [200, 300, 500],\n",
        "    'learning_rate': [1e-4, 5e-4]\n",
        "}\n",
        "\n",
        "# Iterate through each time step, perform grid search, and save the best model\n",
        "for time_steps in time_steps_list:\n",
        "    # Load the data\n",
        "    X_train, X_test, y_train, y_test = load_data(time_steps)\n",
        "\n",
        "    # Define the number of features (assumed to be same for all time steps)\n",
        "    num_features = X_train.shape[2]\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model = None\n",
        "\n",
        "    # Iterate through the parameter grid\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        units = params['units']\n",
        "        learning_rate = params['learning_rate']\n",
        "\n",
        "        # Build the model\n",
        "        model = build_model(units, learning_rate)\n",
        "\n",
        "        # EarlyStopping callback\n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=2,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=300,\n",
        "            batch_size=32,\n",
        "            validation_data=(X_test, y_test),\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Get the validation loss of the best epoch\n",
        "        val_loss = min(history.history['val_loss'])\n",
        "\n",
        "        # Update the best model if the current one is better\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = model\n",
        "\n",
        "    # Save the best model\n",
        "    best_model.save(f'/content/drive/MyDrive/NYSE_Dataset/best_model_time_steps_{time_steps}.h5')\n",
        "\n",
        "    print(f\"Best model for time_steps={time_steps} saved with val_loss={best_val_loss}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz27_95aKC49",
        "outputId": "3aa2f107-0ff1-407c-e752-2aa0b6958ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 2.3540e-05\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6.3109e-04 - val_loss: 1.8739e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 3.6387e-04 - val_loss: 1.5656e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.4534e-04 - val_loss: 2.4485e-05\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.5183e-04 - val_loss: 1.1650e-05\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 2.0857e-04 - val_loss: 7.7757e-06\n",
            "Epoch 7/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.5782e-04 - val_loss: 5.4087e-06\n",
            "Epoch 8/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.5752e-04 - val_loss: 5.9494e-05\n",
            "Epoch 9/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.3766e-04 - val_loss: 1.4559e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 7.5756e-05\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5.9182e-04 - val_loss: 1.7788e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3.3354e-04 - val_loss: 5.0325e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 2.9777e-04 - val_loss: 9.3264e-06\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.8450e-04 - val_loss: 1.8159e-05\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.5250e-04 - val_loss: 1.5158e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 2.7573e-05\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3.1234e-04 - val_loss: 1.8290e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 2.2761e-04 - val_loss: 5.4525e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.4369e-04 - val_loss: 1.7655e-05\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.1439e-04 - val_loss: 1.2542e-05\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.0538e-04 - val_loss: 7.4933e-06\n",
            "Epoch 7/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.5446e-04 - val_loss: 4.6422e-06\n",
            "Epoch 8/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.5232e-04 - val_loss: 1.8356e-05\n",
            "Epoch 9/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.3228e-04 - val_loss: 2.0501e-06\n",
            "Epoch 10/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 9.8610e-05 - val_loss: 1.5569e-05\n",
            "Epoch 11/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6.7457e-05 - val_loss: 2.4755e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0028 - val_loss: 2.3938e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 2.8322e-04 - val_loss: 2.0379e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.9972e-04 - val_loss: 5.0061e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.4576e-04 - val_loss: 1.7792e-04\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0024 - val_loss: 4.1477e-05\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.2692e-04 - val_loss: 2.8488e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.5978e-04 - val_loss: 1.7238e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.2097e-04 - val_loss: 4.4590e-05\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 9.7979e-05 - val_loss: 2.0661e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0023 - val_loss: 4.5774e-06\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.7815e-04 - val_loss: 2.9842e-06\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.6935e-04 - val_loss: 1.6666e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.7842e-04 - val_loss: 6.3584e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model for time_steps=1 saved with val_loss=2.050065631920006e-06.\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 1.1755e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 7.4764e-04 - val_loss: 4.1012e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3.8547e-04 - val_loss: 2.0147e-04\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 1.0824e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.4813e-04 - val_loss: 1.3121e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.8223e-04 - val_loss: 1.1223e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.6224e-04 - val_loss: 3.1703e-05\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.8515e-04 - val_loss: 9.6634e-06\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.5102e-04 - val_loss: 4.4317e-06\n",
            "Epoch 7/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.0978e-04 - val_loss: 7.2306e-06\n",
            "Epoch 8/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.4929e-04 - val_loss: 3.1341e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 4.9817e-05\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3.9937e-04 - val_loss: 5.3864e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 2.9460e-04 - val_loss: 4.3555e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.4225e-04 - val_loss: 3.5169e-05\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.2542e-04 - val_loss: 5.0333e-04\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.4912e-04 - val_loss: 1.5902e-05\n",
            "Epoch 7/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.1484e-04 - val_loss: 1.1252e-05\n",
            "Epoch 8/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.2121e-04 - val_loss: 6.5465e-06\n",
            "Epoch 9/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.0492e-04 - val_loss: 1.7268e-05\n",
            "Epoch 10/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.3841e-04 - val_loss: 5.3418e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 3.6163e-05\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3.1459e-04 - val_loss: 1.0062e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.6454e-04 - val_loss: 1.3069e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 2.3411e-04 - val_loss: 1.2565e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.9790e-04 - val_loss: 2.9034e-04\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0030 - val_loss: 1.2990e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.6846e-04 - val_loss: 1.6884e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.0436e-04 - val_loss: 1.1264e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.6591e-04 - val_loss: 1.0654e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.3359e-04 - val_loss: 1.1793e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0031 - val_loss: 2.7260e-05\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 2.2833e-04 - val_loss: 6.3535e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.7633e-04 - val_loss: 1.5414e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.3343e-04 - val_loss: 2.2270e-05\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.7979e-04 - val_loss: 4.2359e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model for time_steps=2 saved with val_loss=4.431676188687561e-06.\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0126 - val_loss: 0.0011\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0011 - val_loss: 4.0325e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.8183e-04 - val_loss: 1.5569e-04\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.3033e-04 - val_loss: 2.4411e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.7187e-04 - val_loss: 4.3242e-05\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.3510e-04 - val_loss: 3.4572e-05\n",
            "Epoch 7/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.7892e-04 - val_loss: 5.5179e-05\n",
            "Epoch 8/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.2758e-04 - val_loss: 5.9262e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 1.5404e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 6.9288e-04 - val_loss: 2.2892e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.9038e-04 - val_loss: 9.3069e-06\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.6003e-04 - val_loss: 8.4696e-06\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.3467e-04 - val_loss: 5.2953e-05\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.0969e-04 - val_loss: 1.4665e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 4.4712e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.3393e-04 - val_loss: 4.5598e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.3232e-04 - val_loss: 1.4339e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.5571e-04 - val_loss: 3.6922e-05\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.8083e-04 - val_loss: 1.5581e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 1.4509e-05\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.4190e-04 - val_loss: 1.2492e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.7238e-04 - val_loss: 6.0998e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 2.3381e-04 - val_loss: 7.8540e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 7.5195e-05\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 3.3911e-04 - val_loss: 7.1454e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.6696e-04 - val_loss: 3.4174e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.7983e-04 - val_loss: 2.0053e-05\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.8265e-04 - val_loss: 5.8955e-05\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.6531e-04 - val_loss: 7.2438e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 1.7985e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.1499e-04 - val_loss: 4.0805e-06\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.9435e-04 - val_loss: 6.9055e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.2572e-04 - val_loss: 5.8568e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model for time_steps=5 saved with val_loss=4.080453891219804e-06.\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0167 - val_loss: 4.4151e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0012 - val_loss: 3.5757e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.4788e-04 - val_loss: 2.2008e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.5503e-04 - val_loss: 3.5680e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.0381e-04 - val_loss: 1.1446e-05\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.6118e-04 - val_loss: 1.3684e-05\n",
            "Epoch 7/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.1238e-04 - val_loss: 5.4828e-06\n",
            "Epoch 8/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.8117e-04 - val_loss: 7.7995e-06\n",
            "Epoch 9/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.6077e-04 - val_loss: 1.7833e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0096 - val_loss: 8.1385e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 9.1347e-04 - val_loss: 1.3102e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.6946e-04 - val_loss: 3.4825e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.6996e-04 - val_loss: 1.4535e-04\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.0905e-04 - val_loss: 5.8058e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0098 - val_loss: 4.5628e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 6.9021e-04 - val_loss: 8.2265e-06\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.4552e-04 - val_loss: 8.0068e-06\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.4190e-04 - val_loss: 2.1970e-06\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.0269e-04 - val_loss: 2.5511e-05\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.1394e-04 - val_loss: 1.1102e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0070 - val_loss: 2.4592e-05\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.1100e-04 - val_loss: 2.6724e-05\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.9849e-04 - val_loss: 4.2491e-05\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 9.2068e-05\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.6483e-04 - val_loss: 5.0380e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.1942e-04 - val_loss: 1.8146e-05\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.2423e-04 - val_loss: 1.0930e-05\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.5477e-04 - val_loss: 1.9580e-04\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.4361e-04 - val_loss: 1.1089e-04\n",
            "Epoch 1/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 2.9799e-04\n",
            "Epoch 2/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.3317e-04 - val_loss: 1.0125e-04\n",
            "Epoch 3/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.9994e-04 - val_loss: 1.1912e-04\n",
            "Epoch 4/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.1575e-04 - val_loss: 9.8707e-05\n",
            "Epoch 5/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.8386e-04 - val_loss: 2.4412e-05\n",
            "Epoch 6/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.5956e-04 - val_loss: 7.2408e-06\n",
            "Epoch 7/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.4917e-04 - val_loss: 4.0961e-06\n",
            "Epoch 8/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.9168e-04 - val_loss: 9.7224e-05\n",
            "Epoch 9/300\n",
            "\u001b[1m1524/1524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.2382e-04 - val_loss: 1.5394e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model for time_steps=10 saved with val_loss=2.1969660792819923e-06.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df_sf = pd.read_csv('/content/drive/MyDrive/NYSE_Dataset/df_sf.csv')"
      ],
      "metadata": {
        "id": "PsO_5LC9AvF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the five model to select the best one among them"
      ],
      "metadata": {
        "id": "8gNw4kHoKRfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to calculate rRMSE\n",
        "def root_relative_mean_squared_error(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    rrmse = rmse / np.mean(y_true)\n",
        "    return rrmse\n",
        "\n",
        "# Function to load data for a given time step\n",
        "def load_data(time_steps):\n",
        "    dir_path = f'/content/drive/MyDrive/NYSE_Dataset/time_steps_{time_steps}'\n",
        "    X_train = np.load(os.path.join(dir_path, 'X_train.npy'))\n",
        "    X_test = np.load(os.path.join(dir_path, 'X_test.npy'))\n",
        "    y_train = np.load(os.path.join(dir_path, 'y_train.npy'))\n",
        "    y_test = np.load(os.path.join(dir_path, 'y_test.npy'))\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# List of time steps\n",
        "time_steps_list = [1, 2, 5, 10]\n",
        "\n",
        "# Iterate through each time step and visualize actual vs predicted prices\n",
        "for time_steps in time_steps_list:\n",
        "    # Load the data\n",
        "    X_train, X_test, y_train, y_test = load_data(time_steps)\n",
        "\n",
        "    # Load the best model\n",
        "    model_path = f'/content/drive/MyDrive/NYSE_Dataset/best_model_time_steps_{time_steps}.h5'\n",
        "    best_model = load_model(model_path)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    me = np.mean(y_pred - y_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rrmse = root_relative_mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Metrics for time_steps={time_steps}:\")\n",
        "    print(f\"ME: {me:.2f}%\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"MSE: {mse:.4f}\")\n",
        "    print(f\"rRMSE: {rrmse:.4f}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOaNI4TGfCDM",
        "outputId": "af618aea-6d10-452a-9aef-a85696fcf249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for time_steps=1:\n",
            "ME: -0.00%\n",
            "MAE: 0.0012\n",
            "MSE: 0.0000\n",
            "rRMSE: 0.0171\n",
            "\n",
            "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Metrics for time_steps=2:\n",
            "ME: 0.00%\n",
            "MAE: 0.0016\n",
            "MSE: 0.0000\n",
            "rRMSE: 0.0251\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "Metrics for time_steps=5:\n",
            "ME: 0.00%\n",
            "MAE: 0.0016\n",
            "MSE: 0.0000\n",
            "rRMSE: 0.0242\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step\n",
            "Metrics for time_steps=10:\n",
            "ME: 0.00%\n",
            "MAE: 0.0012\n",
            "MSE: 0.0000\n",
            "rRMSE: 0.0177\n",
            "\n"
          ]
        }
      ]
    }
  ]
}